<!DOCTYPE html>
<html  lang=en>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  
    
    <link rel="shortcut icon" href="/images/favicon.ico ">
    
    
    <link rel="icon" type="image/png" href="/images/favicon-android.png " sizes="192x192">
    
    
    <link rel="apple-touch-icon" href="/images/favicon-apple.png " sizes="180x180">
    
  
  <!-- title -->
  <title>Yu Peng blog 第九章 虚拟内存 </title>
  <!-- styles -->
  <!-- styles -->

<link rel="stylesheet" href="/styles/global.css">

  <!-- rss -->
  
<meta name="generator" content="Hexo 6.3.0"></head>
  <body>
    <header id="header">
  
  <nav class="menu menu--right">
  
    <a class="menu__item" href="/">主页</a>
    <a class="menu__item" href="/archives/">归档</a>
    <a class="menu__item" href="/categories/">专题</a>
    <a class="menu__item" href="/tags/">标签</a>
    <a class="menu__item" href="/works/">作品</a>
    <a class="menu__item" href="/about/">关于</a>
  </nav>
</header>
    <main>
      <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post__header">
  <h1 class="post__title">第九章 虚拟内存</h1>
  
  
  <div class="post__meta">
    
<time class="post__date" datetime="2024-06-06T12:48:39.000Z" itemprop="datePublished">
  
  <i class="blogfont">&#xedff;</i>
  
  2024-06-06 20:48:39
</time>

    
<div class="post__category">
  <i class="blogfont">&#xe62d;</i>
  <a class="category-link" href="/categories/csapp/">csapp</a>
</div>
  

    
<div class="post__tag">
  <i class="blogfont">&#xe7ec;</i>
  <a class="tag-link-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a>
</div>


    <div id="/2024/06/06/csapp/chapter9/chapter9/" class="leancloud_visitors post__stat" data-flag-title="第九章 虚拟内存">
  <i class="blogfont">&#xe672;</i>
  <span class="leancloud-visitors-count">loading...</span>
</div>
  </div>
</header>
  <aside class="post__aside">
  <div class="post__actions">
    <a id="backTop" class="post__top" href="javascript:">
      <i class="blogfont">&#xe6b1;</i><!-- Top -->
    </a>
    <a id="share" class="post__share" href="javascript:">
      <i class="blogfont">&#xe6c1;</i>
    </a>
  </div>
  <ol class="post__toc"><li class="post__toc-item post__toc-level-1"><a class="post__toc-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="post__toc-text">虚拟内存</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-1-%E7%89%A9%E7%90%86%E5%92%8C%E8%99%9A%E6%8B%9F%E5%AF%BB%E5%9D%80"><span class="post__toc-text">9.1 物理和虚拟寻址</span></a></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-2-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4"><span class="post__toc-text">9.2 地址空间</span></a></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-3-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98%E7%9A%84%E5%B7%A5%E5%85%B7"><span class="post__toc-text">9.3 虚拟内存作为缓存的工具</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-1-DRAM-%E7%BC%93%E5%AD%98%E7%9A%84%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84"><span class="post__toc-text">9.3.1 DRAM 缓存的组织结构</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-2-%E9%A1%B5%E8%A1%A8"><span class="post__toc-text">9.3.2 页表</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-3-%E9%A1%B5%E5%91%BD%E4%B8%AD"><span class="post__toc-text">9.3.3 页命中</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-4-%E7%BC%BA%E9%A1%B5"><span class="post__toc-text">9.3.4 缺页</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-5-%E5%88%86%E9%85%8D%E9%A1%B5%E9%9D%A2"><span class="post__toc-text">9.3.5 分配页面</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-3-6-%E5%8F%88%E6%98%AF%E5%B1%80%E9%83%A8%E6%80%A7%E6%95%91%E4%BA%86%E6%88%91%E4%BB%AC"><span class="post__toc-text">9.3.6 又是局部性救了我们</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-4-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E4%BD%9C%E4%B8%BA%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%9A%84%E5%B7%A5%E5%85%B7"><span class="post__toc-text">9.4 虚拟内存作为内存管理的工具</span></a></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-5-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E4%BD%9C%E4%B8%BA%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4%E7%9A%84%E5%B7%A5%E5%85%B7"><span class="post__toc-text">9.5 虚拟内存作为内存保护的工具</span></a></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-6-%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91"><span class="post__toc-text">9.6 地址翻译</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-6-1-%E7%BB%93%E5%90%88%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%92%8C%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="post__toc-text">9.6.1 结合高速缓存和虚拟内存</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-6-2-%E5%88%A9%E7%94%A8-TLB-%E5%8A%A0%E9%80%9F%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91"><span class="post__toc-text">9.6.2 利用 TLB 加速地址翻译</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-6-3-%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8"><span class="post__toc-text">9.6.3 多级页表</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-6-4-%E7%BB%BC%E5%90%88%EF%BC%9A%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91"><span class="post__toc-text">9.6.4 综合：端到端的地址翻译</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-7-%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6"><span class="post__toc-text">9.7 案例研究</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-7-1-Core-i7-%E5%9C%B0%E5%9D%80%E7%BF%BB%E8%AF%91"><span class="post__toc-text">9. 7. 1 Core i7 地址翻译</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-8-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84"><span class="post__toc-text">9.8 内存映射</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-8-1-%E5%86%8D%E7%9C%8B%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1"><span class="post__toc-text">9.8.1 再看共享对象</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-8-2-%E5%86%8D%E7%9C%8B-fork-%E5%87%BD%E6%95%B0"><span class="post__toc-text">9.8.2 再看 fork 函数</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-8-3-%E5%86%8D%E7%9C%8B-execve-%E5%87%BD%E6%95%B0"><span class="post__toc-text">9.8.3 再看 execve 函数</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-8-4-%E4%BD%BF%E7%94%A8-mmap-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%88%B7%E7%BA%A7%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84"><span class="post__toc-text">9.8.4 使用 mmap 函数的用户级内存映射</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-9-%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D"><span class="post__toc-text">9.9 动态内存分配</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-9-1-malloc-%E5%92%8C-free-%E5%87%BD%E6%95%B0"><span class="post__toc-text">9.9.1 malloc 和 free 函数</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-9-4-%E7%A2%8E%E7%89%87"><span class="post__toc-text">9.9.4 碎片</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-10-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86"><span class="post__toc-text">9.10 垃圾收集</span></a><ol class="post__toc-child"><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-10-1-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86"><span class="post__toc-text">9.10.1 垃圾收集器的基本知识</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-10-2-Mark-amp-Sweep-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8"><span class="post__toc-text">9.10.2 Mark &amp; Sweep 垃圾收集器</span></a></li><li class="post__toc-item post__toc-level-3"><a class="post__toc-link" href="#9-10-3-C-%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BF%9D%E5%AE%88-Mark-amp-Sweep"><span class="post__toc-text">9.10.3 C 程序的保守 Mark &amp; Sweep</span></a></li></ol></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-11-C-%E7%A8%8B%E5%BA%8F%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%8E%E5%86%85%E5%AD%98%E6%9C%89%E5%85%B3%E7%9A%84%E9%94%99%E8%AF%AF"><span class="post__toc-text">9.11 C 程序中常见的与内存有关的错误</span></a></li><li class="post__toc-item post__toc-level-2"><a class="post__toc-link" href="#9-12-%E5%B0%8F%E7%BB%93"><span class="post__toc-text">9.12 小结</span></a></li></ol></li></ol>
</aside>
  <div class="post__content" itemprop="articleBody">
    <h1 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h1><p>一个系统中的进程是与其他进程共享 CPU 和主存资源的。然而，共享主存会形成一些特殊的挑战。随着对 CPU 需求的增长，进程以某种合理的平滑方式慢了下来。但是如果太多的进程需要太多的内存，那么它们中的一些就根本无法运行。当一个程序没有空间可用时，那就是它运气不好了。内存还很容易被破坏。如果某个进程不小心写了另一个进程使用的内存，它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败。</p>
<p>为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存(VM)。虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。通过一个很清晰的机制，虚拟内存提供了三个重要的能力：1)它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。2)它为每个进程提供了一致的地址空间从而简化了内存管理。3)它保护了每个进程的地址空间不被其他进程破坏。</p>
<p>虚拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默地、自动地工作的，不需要应用程序员的任何干涉。既然虚拟内存在幕后工作得如此之<br>好，为什么程序员还需要理解它呢？有以下几个原因：</p>
<ul>
<li>虚拟内存是核心的</li>
<li>虚拟内存是强大的</li>
<li>虚拟内存是危险的</li>
</ul>
<h2 id="9-1-物理和虚拟寻址"><a href="#9-1-物理和虚拟寻址" class="headerlink" title="9.1 物理和虚拟寻址"></a>9.1 物理和虚拟寻址</h2><p>计算机系统的主存被组织成一个由 M 个连续的字节大小的单元组成的数组。每字节都有一个唯一的物理地址(Physical Address PA)第一个字节的地址为 0, 接下来的字节地址为 1，再下一个为 2, 依此类推。给定这种简单的结构，CPU 访问内存的最自然的方式就是使用物理地址。我们把这种方式称为物理寻址(physical addressing)。图 9-1 展示了一个物理寻址的示例，该示例的上下文是一条加载指令，它读取从物理地址 4 处开始的 4 字节字。当 CPU 执行这条加载指令时，会生成一个有效物理地址，通过内存总线，把它传递给主存。主存取出从物理地址 4 处开始的 4 字节字，并将它返回给 CPU, CPU 会将它存放在一个寄存器里。</p>
<p><img src="/image/caspp/chapter9/9-1.jpg"><br>图 9-1 一个使用物理寻址的系统</p>
<p>早期的 PC 使用物理寻址，而且诸如数字信号处理器、嵌入式微控制器以及 Cray 超级计算机这样的系统仍然继续使用这种寻址方式。然而，现代处理器使用的是一种称为虚拟寻址(virtual addressing)的寻址形式，参见图 9-2。</p>
<p><img src="/image/caspp/chapter9/9-2.jpg"><br>图 9-2 —个使用虚拟寻址的系统</p>
<p>使用虚拟寻址，CPU 通过生成一个虚拟地址(Virtual Address VA)来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译(address translation)。 就像异常处理一样，地址翻译需要 CPU 硬件和操作系统之间的紧密合作。CPU 芯片上叫做内存管理单元(Memory Management Unit,MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。</p>
<h2 id="9-2-地址空间"><a href="#9-2-地址空间" class="headerlink" title="9.2 地址空间"></a>9.2 地址空间</h2><p>地址空间(address space)是一个非负整数地址的有序集合:<br>{0 ,1 , 2 , ··· }<br>如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间(linear address space)。 为了简化讨论，我们总是假设使用的是线性地址空间。在一个带虚拟内存的系统中，CPU 从一个有 N &#x3D;2<sup>n</sup>个地址的地址空间中生成虚拟地址，这个地址空间称为虚拟地址空间(virtual address space) :<br>{0 ,1 , 2 , ···, N-1 }<br>一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含 N&#x3D;2<sup>n</sup>个地址的虚拟地址空间就叫做一个 n 位地址空间。现代系统通常支持 32 位或者 64 位虚拟地址空间。</p>
<p>一个系统还有一个物理地址空间(physical address space)，对应于系统中物理内存的M 个字节：<br>{0 ,1 , 2 , ···, M-1 }<br>M 不要求是 2 的幂，但是为了简化讨论，我们假设M&#x3D;2<sbp>m</sup>。</p>
<p>地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）。 一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间。这就是虚拟内存的基本思想。主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。</p>
<h2 id="9-3-虚拟内存作为缓存的工具"><a href="#9-3-虚拟内存作为缓存的工具" class="headerlink" title="9.3 虚拟内存作为缓存的工具"></a>9.3 虚拟内存作为缓存的工具</h2><p>概念上而言，虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被缓存在主存中。和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存(较高层）之间的传输单元。VM 系统通过将虚拟内存分割为称为虚拟页（Virtual Page, VP)的大小固定的块来处理这个问题。每个虚拟页的大小为 字节。类似地，物理内存被分割为物理页(Physical Page, PP)。大小也为 P 字节（物理页也被称为页帧(page frame)）。</p>
<p>在任意时刻，虚拟页面的集合都分为三个不相交的子集：</p>
<ul>
<li>未分配的</li>
<li>缓存的</li>
<li>未缓存的</li>
</ul>
<p>图 9-3 的示例展示了一个有 8 个虚拟页的小虚拟内存。虚拟页 0 和 3 还没有被分配，因此在磁盘上还不存在。虚拟页 1、4 和 6 被缓存在物理内存中。页 2、5 和 7 已经被分配了，但是当前并未缓存在主存中。</p>
<p><img src="/image/caspp/chapter9/9-3.jpg"><br>图 9-3 —个 VM 系统是如何使用主存作为缓存的</p>
<h3 id="9-3-1-DRAM-缓存的组织结构"><a href="#9-3-1-DRAM-缓存的组织结构" class="headerlink" title="9.3.1 DRAM 缓存的组织结构"></a>9.3.1 DRAM 缓存的组织结构</h3><p>为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语 SRAM 缓存来表示位于 CPU 和主存之间的 Ll、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页。</p>
<p>在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。回想一下，DRAM 比 SRAM 要 慢大约 10 倍，而磁盘要比 DRAM 慢大约 100 000 多倍。因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多，这是因为 DRAM 缓存不命中要由磁盘来服务，而 SRAM 缓存不命中通常是由基于 DRAM 的主存来服务的。而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约100 000 倍。归根到底，DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的。</p>
<p>因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4KB~2MB。由于大的不命中处罚，DRAM 缓存是全相联的，即任何虚拟页都可以放置在任何的物理页中。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因此，与硬件对 SRAM 缓存相比，操作系统对 DRAM 缓存使用了更复杂精密的替换算法。（这些替换算法超出了我们的讨论范围）。 最后，因为对磁盘的访问时间很长，DRAM 缓存总是使用写回，而不是直写。</p>
<h3 id="9-3-2-页表"><a href="#9-3-2-页表" class="headerlink" title="9.3.2 页表"></a>9.3.2 页表</h3><p>同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM 中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。</p>
<p>这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表（page table)的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间来回传送页。</p>
<p>图 9-4 展示了一个页表的基本组织结构。页表就是一个页表条目(Page Table Entry PTE)的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。为了我们的目的，我们将假设每个 PTE 是由一个有效位(valid bit)和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 DRAM 中。如果设置了有效位，那么地址字段就表示 DRAM 中相应的物理页的起始位置，这个物理页中缓存了该虚拟页。如果没有设置有效位，那么一个空地址表示这个虚拟页还未被分配。否则，这个地址就指向该虚拟页在磁盘上的起始位置。图 9-4 中的示例展示了一个有 8 个虚拟页和 4 个物理页的系统的页表。四个虚拟页(VP 1、VP 2、VP 4 和 VP7)当前被缓存在 DRAM 中。两个页(VPO 和 VP5)还未被分配，而剩下的页(VP 3 和 VP 6)已经被分配了，但是当前还未被缓存。图 9-4 中有一个要点要注意，因为 DRAM 缓存是全相联的，所以任意物理页都可以包含任意虚拟页。</p>
<p><img src="/image/caspp/chapter9/9-4.jpg"><br>图 9-4 页表</p>
<h3 id="9-3-3-页命中"><a href="#9-3-3-页命中" class="headerlink" title="9.3.3 页命中"></a>9.3.3 页命中</h3><p>考虑一下当 CPU 想要读包含在 VP 2 中的虚拟内存的一个字时会发生什么（图 9-5），VP2 被缓存在 DRAM 中。使用我们将在 9.6 节中详细描述的一种技术，地址翻译硬件将虚拟地址作为一个索引来定位 PTE 2, 并从内存中读取它。因为设置了有效位，那么地址翻译硬件就知道 VP 2 是缓存在内存中的了。所以它使用 PTE 中的物理内存地址（该地址指向 PP1中缓存页的起始位置）， 构造出这个字的物理地址。</p>
<p><img src="/image/caspp/chapter9/9-5.jpg"><br>图 9-5 VM 页命中。对 VP2 中一个字的引用就会命中</p>
<h3 id="9-3-4-缺页"><a href="#9-3-4-缺页" class="headerlink" title="9.3.4 缺页"></a>9.3.4 缺页</h3><p>在虚拟内存的习惯说法中，DRAM 缓存不命中称为缺页(page fault)。图 9-6 展示了在缺页之前我们的示例页表的状态。CPU 引用了 VP 3 中的一个字，VP 3 并未缓存在DRAM 中。地址翻译硬件从内存中读取 PTE 3, 从有效位推断出 VP 3 未被缓存，并且触发一个缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页，在此例中就是存放在 PP 3 中的 VP 4。如果 VP 4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP 4 的页表条目，反映出 VP 4 不再缓存在主存中这一事实。</p>
<p><img src="/image/caspp/chapter9/9-6.jpg"><br>图 9-6 VM 缺页（之前）。 对 VP 3 中的字的引用会不命中，从而触发了缺页</p>
<p>接下来，内核从磁盘复制 VP 3 到内存中的 PP 3, 更新 PTE 3，随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在，VP 3 已经缓存在主存中了，那么页命中也能由地址翻译硬件正常处理了。图 9-7 展示了在缺页之后我们的示例页表的状态。</p>
<p><img src="/image/caspp/chapter9/9-7.jpg"><br>图 9-7 VM 缺页（之后）。 缺页处理程序选择 VP 4 作为牺牲页，并从磁盘上用 VP 3 的副本取代它。在缺页<br>处理程序重新启动导致缺页的指令之后，该指令将从内存中正常地读取字，而不会再产生异常</p>
<p>虚拟内存是在 20 世纪 60 年代早期发明的，远在 CPU-内存之间差距的加大引发产生SRAM 缓存之前。因此，虚拟内存系统使用了和 SRAM 缓存不同的术语，即使它们的许多概念是相似的。在虚拟内存的习惯说法中，块被称为页。在磁盘和内存之间传送页的活动叫做交换(swapping)或者页 面调度(paging)。页从磁盘换入（或者页面调入）DRAM 和从DRAM 换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为按需页 面调度(demand paging)。也可以采用其他的方法，例如尝试着预测不命中，在页面实际被引用之前就换人页面。然而，所有现代系统都使用的是按需页面调度的方式。</p>
<h3 id="9-3-5-分配页面"><a href="#9-3-5-分配页面" class="headerlink" title="9.3.5 分配页面"></a>9.3.5 分配页面</h3><p>图 9-8 展示了当操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。在这个示例中，VP5 的分配过程是在磁盘上创建空间并更新 PTE 5, 使它指向磁盘上这个新创建的页面。</p>
<p><img src="/image/caspp/chapter9/9-8.jpg"><br>图 9-8 分配一个新的虚拟页商。内核在磁盘上分配 VP5，并且将 PTE 5 指向这个新的位置</p>
<h3 id="9-3-6-又是局部性救了我们"><a href="#9-3-6-又是局部性救了我们" class="headerlink" title="9.3.6 又是局部性救了我们"></a>9.3.6 又是局部性救了我们</h3><p>只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。但是，当然不是所有的程序都能展现良好的时间局部性。如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动(thrashing), 这时页面将不断地换进换出。虽然虚拟内存通常是有效的，但是如果一个程序性能慢得像爬一样，那么聪明的程序员会考虑是不是发生了抖动。</p>
<blockquote>
<p>你可以利用 Linux 的 getrusage 函数监测缺页的数量（以及许多其他的信息）。</p>
</blockquote>
<h2 id="9-4-虚拟内存作为内存管理的工具"><a href="#9-4-虚拟内存作为内存管理的工具" class="headerlink" title="9.4 虚拟内存作为内存管理的工具"></a>9.4 虚拟内存作为内存管理的工具</h2><p>在上一节中，我们看到虚拟内存是如何提供一种机制，利用 DRAM 缓存来自通常更大的虚拟地址空间的页面。有趣的是，一些早期的系统，比如 DEC PDP-11&#x2F;70, 支持的是一个比物理内存更小的虚拟地址空间。然而，虚拟地址仍然是一个有用的机制，因为它大大地简化了内存管理，并提供了一种自然的保护内存的方法。</p>
<p>到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间。图 9-9展示了基本思想。在这个示例中，进程 i 的页表将 V P1 映射到 PP 2, VP 2 映射到 PP 7。相似地，进程j的页表将VP 1 映射到 PP 7，VP 2 映射到 PP10。注意，多个虚拟页面可以映射到同一个共享物理页面上。</p>
<p><img src="/image/caspp/chapter9/9-9.jpg"><br>图 9-9 VM 如何为进程提供独立的地址空间。操作系统为系统中的每个进程都维护一个独立的页表</p>
<p>按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别地，VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配。</p>
<ul>
<li>简化链接</li>
<li>简化加载</li>
<li>简化共享</li>
<li>简化内存分配</li>
</ul>
<h2 id="9-5-虚拟内存作为内存保护的工具"><a href="#9-5-虚拟内存作为内存保护的工具" class="headerlink" title="9.5 虚拟内存作为内存保护的工具"></a>9.5 虚拟内存作为内存保护的工具</h2><p>任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许一个用户进程修改它的只读代码段。而且也不应该允许它读或修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）。</p>
<p>就像我们所看到的，提供独立的地址空间使得区分不同进程的私有内存变得容易。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE.所以通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。图 9-10 展示了大致的思想。</p>
<p><img src="/image/caspp/chapter9/9-10.jpg"><br>图 9-10 用虚拟内存来提供页面级的内存保护</p>
<p>在这个示例中，每个 PTE 中已经添加了三个许可位。SUP 位表示进程是否必须运行在内核(超级用户）模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面。READ 位和 WRITE 位控制对页面的读和写访问。例如，如果进程 i 运行在用户模式下，那么它有读 VPO 和读写VP1的权限。然而，不允许它访问 VP2。</p>
<p>如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell —般将这种异常报告为“段错误（segmentation fault)。</p>
<h2 id="9-6-地址翻译"><a href="#9-6-地址翻译" class="headerlink" title="9.6 地址翻译"></a>9.6 地址翻译</h2><p><img src="/image/caspp/chapter9/9-11.jpg"><br>图 9-11 地址翻译符号小结</p>
<p>形式上来说，地址翻译是一个 N 元素的虚拟地址空间(VAS)中的元素和一个 M 元素的物理地址空间(PAS)中元素之间的映射，</p>
<blockquote>
<p>MAP:VAS -&gt; PAS U ∅ </p>
</blockquote>
<p>图 9-12 展示了 MMU 如何利用页表来实现这种映射。CPU 中的一个控制寄存器，页表基址寄存器(Page Table Base Register, PTBR)指向当前页表。n 的虚拟地址包含两个部分:一个 p 位的虚拟页 面偏移(Virtual Page Offset，VPO)和一个(n-p)位的虚拟页号(Virtual Page Number, VPN)。MMU 利用VPN 来选择适当的 PTE, 例如，VPNO 选择 PTEO, VPN1选择 PTE1。以此类推。将页表条目中物理页号(Physical Page Number, PPN)和虚拟地址中的 VPO 串联起来，就得到相应的物理地址。注意，因为物理和虚拟页面都是 P 字节的，所以物理页面偏移(Physical Page Offset, PPO)和 VPO 是相同的。</p>
<p><img src="/image/caspp/chapter9/9-12.jpg"><br>图 9-12 使用页表的地址翻译</p>
<h3 id="9-6-1-结合高速缓存和虚拟内存"><a href="#9-6-1-结合高速缓存和虚拟内存" class="headerlink" title="9.6.1 结合高速缓存和虚拟内存"></a>9.6.1 结合高速缓存和虚拟内存</h3><p>在任何既使用虚拟内存又使用 SRAM 髙速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。尽管关于这个折中的详细讨论已经超出了我们的讨论范围，但是大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，高速缓存无需处理保护问题，因为访问权限的检査是地址翻译过程的一部分。</p>
<p>图 9-14 展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要的思路是地址翻译发生在高速缓存查找之前。注意，页表条目可以缓存，就像其他的数据字一样。</p>
<p><img src="/image/caspp/chapter9/9-14.jpg"><br>图 9-14 将 VM 与物理寻址的高速缓存结合起来（VA: 虚拟地址。PTEA: 页表条目地址。PTE: 页表条目。PA: 物理地址）</p>
<h3 id="9-6-2-利用-TLB-加速地址翻译"><a href="#9-6-2-利用-TLB-加速地址翻译" class="headerlink" title="9.6.2 利用 TLB 加速地址翻译"></a>9.6.2 利用 TLB 加速地址翻译</h3><p>正如我们看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE, 以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期。如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 1 个或 2 个周期。然而，许多系统都试图消除即使是这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为翻译后备缓冲器(Translation Lookaside Buffer, TLB)。</p>
<p>TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度。如图 9-15 所示，用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的。如果 TLB 有：T&#x3D;2<sup>t</sup>个组，那么 TLB 索引(TLBI)是由VPN 的 t 个最低位组成的，而 TLB 标记(TLBT)是由 VPN 中剩余的位组成的。</p>
<p><img src="/image/caspp/chapter9/9-15.jpg"><br>图 9-15 虚拟地址中用以访问 TLB 的组成部分</p>
<h3 id="9-6-3-多级页表"><a href="#9-6-3-多级页表" class="headerlink" title="9.6.3 多级页表"></a>9.6.3 多级页表</h3><p>到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译。但是如果我们有一个 32 位的地址空间、4KB 的页面和一个 4 字节的 PTE。那么即使应用所引用的只是虚拟地址空间中很小的一部分，也总是需要一个 4MB 的页表驻留在内存中。对于地址空间为 64 位的系统来说，问题将变得更复杂。</p>
<p>用来压缩页表的常用方法是使用层次结构的页表。用一个具体的示例是最容易理解这个思想的。假设 32 位虚拟地址空间被分为 4KB 的页，而每个页表条目都是 4 字节。还假设在这一时刻，虚拟地址空间有如下形式：内存的前 2K 个页面分配给了代码和数据，接下来的 6K 个页面还未分配，再接下来的 1023 个页面也未分配，接下来的 1 个页面分配给了用户栈。图 9-17 展示了我们如何为这个虚拟地址空间构造一个两级的页表层次结构。</p>
<p><img src="/image/caspp/chapter9/9-17.jpg"><br>图 9-17 一个两级页表层次结构。注意地址是从上往下增加的</p>
<h3 id="9-6-4-综合：端到端的地址翻译"><a href="#9-6-4-综合：端到端的地址翻译" class="headerlink" title="9.6.4 综合：端到端的地址翻译"></a>9.6.4 综合：端到端的地址翻译</h3><p>在这一节里，我们通过一个具体的端到端的地址翻译示例，来综合一下我们刚学过的这些内容，这个示例运行在有一个 TLB 和 Lid-cache 的小系统上。为了保证可管理性，我们做出如下假设：</p>
<ul>
<li>内存是按字节寻址的。</li>
<li>内存访问是针对 1 字节的字的(不是 4 字节的字)。</li>
<li>虚拟地址是 14 位长的(U&#x3D;14)。</li>
<li>物理地址是 12 位长的(m&#x3D;12)。</li>
<li>页面大小是 64 字节(P&#x3D;64)。</li>
<li>TLB 是四路组相联的，总共有 16 个条目。</li>
<li>Lid-cache 是物理寻址、直接映射的，行大小为 4 字节，而总共有 16 个组。</li>
</ul>
<p>图 9-19 展示了虚拟地址和物理地址的格式。因为每个页面是 字节，所以虚拟地址和物理地址的低 6 位分别作为 VPO 和 PPO 。虚拟地址的高 8 位作为 VPN, 物理地址的高 6 位作为 PPN。</p>
<p><img src="/image/caspp/chapter9/9-19.jpg"><br>图 9-19 小内存系统的寻址。假设 14 位的虚拟地址(n&#x3D;14),12 位的物理地址(m&#x3D;12)和 64 字节的页面(P&#x3D;64)</p>
<p>图 9-20 展示了小内存系统的一个快照，包括 TLB(图 9-20a)。 页表的一部分（图 9-20b）和 L1 高速缓存（图 9-20e）， 在 TLB 和高速缓存的图上面，我们还展示了访问这些设备时硬件是如何划分虚拟地址和物理地址的位的。</p>
<p><img src="/image/caspp/chapter9/9-20.jpg"><br>图 9-20 小内存系统的 TLB。页表以及缓存。TLB。页表和缓存中所有的值都是十六进制表示的</p>
<p>给定了这种初始化设定，让我们来看看当 CPU 执行一条读地址 0x03d4 处字节的加载指令时会发生什么。（回想一下我们假定 CPU 读取 1 字节的字，而不是 4 字节的字。）为了开始这种手工的模拟，我们发现写下虚拟地址的各个位，标识出我们会需要的各种字段，并确定它们的十六进制值，是非常有帮助的》 当硬件解码地址时，它也执行相似的任务。</p>
<p><img src="/image/caspp/chapter9/9-20.1.jpg"></p>
<p>开始时，MMU 从虚拟地址中抽取出 VPN(0x0F), 并且检查 TLB, 看它是否因为前面的某个内存引用缓存了 PTE 0x0F 的一个副本。TLB 从 VPN 中抽取出 TLB 索引(0x03)和 TLB 标记(0x3)，组 0x3 的第二个条目中有效匹配，所以命中，然后将缓存的 PPN(OxOD)返回给 MMU。</p>
<p>如果 TLB 不命中，那么 MMU 就需要从主存中取出相应的 PTE 然而，在这种情况中，我们很幸运，TLB 会命中。现在，MMU 有了形成物理地址所需要的所有东西。它通过将来自 PTE 的 PPN(0x0D)和来自虚拟地址的 VPO(0x14)连接起来，这就形成了物理地址(0x354)。</p>
<p>接下来，MMU 发送物理地址给缓存，缓存从物理地址中抽取出缓存偏移 CO(0x0)、缓存组索引 CI(0x5)以及缓存标记 CT(0X0D)。</p>
<p><img src="/image/caspp/chapter9/9-20.2.jpg"></p>
<p>B为组 0x5 中的标记与 CT 相匹配，所以缓存检测到一个命中，读出在偏移量 CO 处的数据字节(0x36)，并将它返回给 MMU。随后 MMU 将它传递回 CPU。翻译过程的其他路径也是可能的。例如，如果 TLB 不命中，那么 MMU 必须从页表中的 PTE 中取出 PPN。如果得到的 PTE 是无效的，那么就产生一个缺页，内核必须调入合适的页面，重新运行这条加载指令。另一种可能性是 PTE 是有效的，但是所需要的内存块在缓存中不命中。</p>
<h2 id="9-7-案例研究"><a href="#9-7-案例研究" class="headerlink" title="9.7 案例研究"></a>9.7 案例研究</h2><h3 id="9-7-1-Core-i7-地址翻译"><a href="#9-7-1-Core-i7-地址翻译" class="headerlink" title="9. 7. 1 Core i7 地址翻译"></a>9. 7. 1 Core i7 地址翻译</h3><p>图 9-22 总结了完整的 Core i7 地址翻译过程，从 CPU 产生虚拟地址的时刻一直到来自内存的数据字到达 CPU。Core i7 采用四级页表层次结构。每个进程有它自己私有的页表层次结构。当一个 Linux 进程在运行时，虽然 Core i7 体系结构允许页表换进换出，但是与已分配了的页相关联的页表都是驻留在内存中的。CR3 控制寄存器指向第一级页表(L1)的起始位置。CR3 的值是每个进程上下文的一部分，每次上下文切换时，CR3 的值都会被恢复。</p>
<p><img src="/image/caspp/chapter9/9-21.jpg"><br>图 9-21 Core i7 的内存系统<br><img src="/image/caspp/chapter9/9-22.jpg"><br>图 9-22 Core i7 地址翻译的概况。为了简化，没有显示 i-cache、 i-TLB 和 L2 统一 TLB</p>
<h2 id="9-8-内存映射"><a href="#9-8-内存映射" class="headerlink" title="9.8 内存映射"></a>9.8 内存映射</h2><p>Linux 通过将一个虚拟内存区域与一个磁盘上的对象(object)关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射(memory mapping)。虚拟内存区域可以映射到两种类型的对象中的一种：</p>
<ol>
<li>Linux 文件 系统中的普通文件：</li>
<li>匿名文件:</li>
</ol>
<p>无论在哪种情况中 旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的交换文件(swap file)之间换来换去。交换文件也叫做交换空间(swap space)或者交换区域(swap area)需要意识到的很重要的一点是，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。</p>
<h3 id="9-8-1-再看共享对象"><a href="#9-8-1-再看共享对象" class="headerlink" title="9.8.1 再看共享对象"></a>9.8.1 再看共享对象</h3><p>一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。而且，这些变化也会反映在磁盘上的原始对象中。</p>
<p>另一方面，对于一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域。</p>
<p>假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中，如图 9-29a 所示。现在假设进程 2 将同一个共享对象映射到它的地址空间（并不一定要和进程 1 在相同的虚拟地址处，如图 9-29b 所示）。</p>
<p><img src="/image/caspp/chapter9/9-29.jpg"><br>图 9-29 个共享对象（注意，物理页面不一定是连续的）</p>
<p>因为每个对象都有一个唯一的文件名，内核可以迅速地判定进程 1 已经映射了这个对象，而且可以使进程 2 中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理内存中也只需要存放共享对象的一个副本。为了方便，我们将物理页面显示为连续的，但是在一般情况下当然不是这样的。</p>
<p>私有对象使用一种叫做写时复制(copy-on-write)的巧妙技术被映射到虚拟内存中。一个私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存有私有对象的一份副本。比如，图 9-30a 展示了一种情况，其中两个进程将一个私有对象映射到它们虚拟内存的不同区域，但是共享这个对象同一个物理副本。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。</p>
<p>当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的可写权限，如图 9-30b 所示。当故障处理程序返回时，CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。</p>
<p>通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物理内存。</p>
<p><img src="/image/caspp/chapter9/9-30.jpg"><br>图 9-30 —个私有的写时复制对象</p>
<h3 id="9-8-2-再看-fork-函数"><a href="#9-8-2-再看-fork-函数" class="headerlink" title="9.8.2 再看 fork 函数"></a>9.8.2 再看 fork 函数</h3><p>当 fork 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID 为了给这个新进程创建虚拟内存，它创建了当前进程的mm_struct构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制。</p>
<p>当 fork 在新进程中返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。</p>
<h3 id="9-8-3-再看-execve-函数"><a href="#9-8-3-再看-execve-函数" class="headerlink" title="9.8.3 再看 execve 函数"></a>9.8.3 再看 execve 函数</h3><p>虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。既然已经理解了这些概念，我们就能够理解 execve 函数实际上是如何加载和执行程序的。假设运行在当前进程中的程序执行了如下的 execve 调用:</p>
<blockquote>
<p>execve(“a.out”, NULL, NULL);</p>
</blockquote>
<p>正如在第 8章中学到的， 函数在当前进程中加载并运行包含在可执行目标文件a.out中的程序，用 a.out 程序有效地替代了当前程序。加载并运行 a.out 需要以下几个步骤:</p>
<ul>
<li>删除已存在的用户区域。</li>
<li>映射私有区域</li>
<li>映射共享区域</li>
<li>设置程序计数器(PC)</li>
</ul>
<p>下一次调度这个进程时，它将从这个入口点开始执行。Linux 将根据需要换入代码和数据页面。</p>
<p><img src="/image/caspp/chapter9/9-31.jpg"><br>图 9-31 加载器是如何映射用户地址空间的区域的</p>
<h3 id="9-8-4-使用-mmap-函数的用户级内存映射"><a href="#9-8-4-使用-mmap-函数的用户级内存映射" class="headerlink" title="9.8.4 使用 mmap 函数的用户级内存映射"></a>9.8.4 使用 mmap 函数的用户级内存映射</h3><p>Linux 进程可以使用 _P函数来创建新的虚拟内存区域，并将对象映射到这些区域中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">mmap</span><span class="params">(<span class="type">void</span> *staxt, <span class="type">size_t</span> length, <span class="type">int</span> prot, <span class="type">int</span> flags,</span></span><br><span class="line"><span class="params"><span class="type">int</span> fd, <span class="type">off_t</span> offset)</span>;</span><br><span class="line"><span class="comment">// 返回：若成功时则为指向映射区域的指针，若出错则为 MAP_FAILED(—1)。</span></span><br></pre></td></tr></table></figure>

<p>mmap 函数要求内核创建一个新的虚拟内存区域，最好是从地址 start 开始的一个区域，并将文件描述符 fd 指定的对象的一个连续的片(chunk)映射到这个新的区域。连续的对象片大小为 length 字节，从距文件开始处偏移量为 offset 字节的地方开始。start地址仅仅是一个暗示，通常被定义为 NULL。为了我们的目的，我们总是假设起始地址为NULL。图 9-32 描述了这些参数的意义。</p>
<p><img src="/image/caspp/chapter9/9-32.jpg"><br>图 9-32 iranap 参数的可视化解释</p>
<p>参数 prot 包含描述新映射的虚拟内存区域的访问权限位（即在相应区域结构中的prot 位）。</p>
<ul>
<li>PROT_EXEC: 这个区域内的页面由可以被 CPU 执行的指令组成。</li>
<li>PROT-READ: 这个区域内的页面可读。</li>
<li>PROT_WRITE: 这个区域内的页面可写，</li>
<li>PROT_NONE: 这个区域内的页面不能被访问。</li>
</ul>
<p>参数 flags 由描述被映射对象类型的位组成。如果设置了 MAP_ANON 标记位，那么被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制零的。MAP_PRIVATE 表示被映射的对象是一个私有的、写时复制的对象，而 MAP_SHARED 表示是一个共享对象。例如</p>
<blockquote>
<p>bufp &#x3D; Mmap(NULL, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);</p>
</blockquote>
<p>让内核创建一个新的包含 size 字节的只读、私有、请求二进制零的虚拟内存区域。如果调用成功，那么 bufp 包含新区域的地址。</p>
<p>munmap 函数删除虚拟内存的区域：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/mman.li&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">munmap</span><span class="params">(<span class="type">void</span> *staxt, <span class="type">size_t</span> length)</span>;</span><br><span class="line"><span class="comment">// 返回：若成功则为 0, 若出错则为 一1,</span></span><br></pre></td></tr></table></figure>

<p>munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域。接下来对已删除区域的引用会导致段错误。</p>
<h2 id="9-9-动态内存分配"><a href="#9-9-动态内存分配" class="headerlink" title="9.9 动态内存分配"></a>9.9 动态内存分配</h2><p>虽然可以使用低级的 mmap 和 munmap 函数来创建和删除虚拟内存的区域，但是 C 程序员还是会觉得当运行时需要额外虚拟内存时，用动 态内存分配器(dynamic memory allocator)更方便，也有更好的可移植性。</p>
<p>动态内存分配器维护着一个进程的虚拟内存区域，称为堆(heap)(见图 9-33)。系统之间细节不同，但是不失通用性，假设堆是一个请求二进制零的区域，它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址）。 对于每个进程，内核维护着一个变量 brk(读做break)。 它指向堆的顶部。</p>
<p><img src="/image/caspp/chapter9/9-33.jpg"><br>图 9-33 堆</p>
<p>分配器将堆视为一组不同大小的块(block)的集合来维护。每个块就是一个连续的虚拟内存片(chunk),要么是已分配的，要么是空闲的。已分配的块显式地保留为供应用程序使用。空闲块可用来分配。空闲块保持空闲，直到它显式地被应用所分配。一个已分配的块保持已分配状态，直到它被释放，这种释放要么是应用程序显式执行的，要么是内存分配器自身隐式执行的。</p>
<p>分配器有两种基本风格。两种风格都要求应用显式地分配块。它们的不同之处在于由哪个实体来负责释放已分配的块。</p>
<ul>
<li>显式分配器</li>
<li>隐式分配器</li>
</ul>
<h3 id="9-9-1-malloc-和-free-函数"><a href="#9-9-1-malloc-和-free-函数" class="headerlink" title="9.9.1 malloc 和 free 函数"></a>9.9.1 malloc 和 free 函数</h3><p>C 标准库提供了一个称为 malloc 程序包的显式分配器。程序通过调用 malloc 函数来从堆中分配块。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">malloc</span><span class="params">(<span class="type">size_t</span> size)</span>;</span><br><span class="line"><span class="comment">// 返回：若成功则为已分配块的指针，若出错则为 NULL</span></span><br></pre></td></tr></table></figure>

<p>malloc 函数返回一个指针，指向大小为至少 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象类型做对齐。实际中，对齐依赖于编译代码在 32 位模式(gcc-m32)还是 64 位模式（默认的）中运行。在 32 位模式中，malloc 返回的块的地址总是 8 的倍数。在 64 位模式中，该地址总是 16 的倍数。</p>
<p>如果 malloc 遇到问题（例如，程序要求的内存块比可用的虚拟内存还要大），那么它就返回 NULL,并设置 errno。malloc 不初始化它返回的内存。那些想要已初始化的动态内存的应用程序可以使用 calloc,calloc 是一个基于 malloc 的瘦包装函数，仓将分配的内存初始化为零。想要改变一个以前已分配块的大小，可以使用 realloc 函数。</p>
<p>动态内存分配器，例如 malloc,可以通过使用 mmap 和 munmap 函数，显式地分配和释放堆内存，或者还可以使用 sbrk 函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">sbrk</span><span class="params">(<span class="type">intptr_t</span> incr)</span>;</span><br><span class="line"><span class="comment">// 返回：若成功則 为旧的 brk 指针，若出错则为一1。</span></span><br></pre></td></tr></table></figure>

<p>sbrk 函数通过将内核的 brk 指针增加 incr 来扩展和收缩堆。如果成功，它就返回brk 的旧值，否则，它就返回-1,并将 errno设置为 ENOMEM。如果 incr 为零，那么sbrk 就返回 brk 的当前值。用一个为负的 incr 来调用 sbrk 是合法的，而且很巧妙，因为返回值（brk 的旧值）指向距新堆顶向上 abs(incr)字节处。</p>
<p>程序是通过调用 free 函数来释放已分配的堆块。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">free</span><span class="params">(<span class="type">void</span> *ptr)</span>;</span><br><span class="line"><span class="comment">// 返回：无，</span></span><br></pre></td></tr></table></figure>

<p>ptr 参数必须指向一个从 malloc、calloc 或者 realloc 获得的已分配块的起始位置。如果不是，那么 free 的行为就是未定义的。更糟的是，既然它什么都不返回，free就不会告诉应用出现了错误。就像我们将在 9.11 节里看到的，这会产生一些令人迷惑的运行时错误。</p>
<p>图 9-34 展示了一个 malloc 和 free 的实现是如何管理一个 C 程序的 16 字的（非常）小的堆的。每个方框代表了一个 4 字节的字。粗线标出的矩形对应于已分配块（有阴影的）和空闲块（无阴影的）。 初始时，堆是由一个大小为 16 个字的、双字对齐的、空闲块组成的。（本节中，我们假设分配器返回的块是 8 字节双字边界对齐的。）</p>
<p><img src="/image/caspp/chapter9/9-34.jpg"><br>图 9-34 用 malloc 和 free 分配和释放块。每个方框对应于一个字。每个粗线标出的矩形对应于一个块。阴影部分是已 分配的块。已分配的块的填充区域是深阴影的。无阴影部分是空闲块。堆地址是从左往右增加的</p>
<h3 id="9-9-4-碎片"><a href="#9-9-4-碎片" class="headerlink" title="9.9.4 碎片"></a>9.9.4 碎片</h3><ul>
<li>隐式空闲链表</li>
<li>放置已分配的块</li>
<li>分割空闲块</li>
<li>获取额外的堆内存</li>
<li>合并空闲块</li>
<li>带边界标记的合并</li>
</ul>
<h2 id="9-10-垃圾收集"><a href="#9-10-垃圾收集" class="headerlink" title="9.10 垃圾收集"></a>9.10 垃圾收集</h2><p>垃圾收集器(garbage collector)是一种动态内存分配器，它自动释放程序不再需要的已分配块。这些块被称为垃圾(garbage)(因此术语就称之为垃圾收集器）。 自动回收堆存储的过程叫做垃圾收集（garbage collection)。 在一个支持垃圾收集的系统中，应用显式分配堆块，但是从不显示地释放它们。在 C 程序的上下文中，应用调用 malloc。但是从不调用 free。反之，垃圾收集器定期识别垃圾块，并相应地调用 free, 将这些块放回到空闲链表中。</p>
<p>垃圾收集可以追溯到 John McCarthy 在 20 世纪 60 年代早期在 MIT 开发的 Lisp 系统。它是诸如 Java、 MLPerl 和 Mathematica 等现代语言系统的一个重要部分，而且它仍然是一个重要而活跃的研究领域。有关文献描述了大量的垃圾收集方法，其数量令人吃惊。我们的讨论局限于 McCarthy 独创的 Mark&amp;Sweep(标记&amp;清除)算法，这个算法很有趣，因为它可以建立在已存在的 malloc 包的基础之上，为 C 和 C++ 程序提供垃圾收集。</p>
<h3 id="9-10-1-垃圾收集器的基本知识"><a href="#9-10-1-垃圾收集器的基本知识" class="headerlink" title="9.10.1 垃圾收集器的基本知识"></a>9.10.1 垃圾收集器的基本知识</h3><p>垃圾收集器将内存视为一张有向可达图(reachability graph), 其形式如图 9-49 所示。该图的节点被分成一组根节点(root node)和一组堆节点(heap node)。 每个堆节点对应于堆中的一个已分配块。有向边 意味着块 f 中的某个位置指向块 9 中的某个位置。根节点对应于这样一种不在堆中的位置，它们中包含指向堆中的指针。这些位置可以是寄存器、栈里的变量，或者是虚拟内存中读写数据区域内的全局变量。</p>
<p><img src="/image/caspp/chapter9/9-49.jpg"><br>图 9-49 垃圾收集器将内存视为一张有向图</p>
<p>当存在一条从任意根节点出发并到达 P 的有向路径时，我们说节点 P 是可达的(reachable)。 在任何时刻，不可达节点对应于垃圾，是不能被应用再次使用的。垃圾收集器的角色是维护可达图的某种表示，并通过释放不可达节点且将它们返回给空闲链表，来定期地回收它们。</p>
<h3 id="9-10-2-Mark-amp-Sweep-垃圾收集器"><a href="#9-10-2-Mark-amp-Sweep-垃圾收集器" class="headerlink" title="9.10.2 Mark &amp; Sweep 垃圾收集器"></a>9.10.2 Mark &amp; Sweep 垃圾收集器</h3><p>Mark &amp; Sweep 垃圾收集器由标记(mark)阶段和清除(sweep)阶段组成，标记阶段标记出根节点的所有可达的和已分配的后继，而后面的清除阶段释放每个未被标记的已分配块。块头部中空闲的低位中的一位通常用来表示这个块是否被标记了。</p>
<p><img src="/image/caspp/chapter9/9-52.jpg"><br>图 9-52 Mark&amp;Sweep 示例。注意这个示例中的箭头表示内存引用，而不是空闲链表指针</p>
<h3 id="9-10-3-C-程序的保守-Mark-amp-Sweep"><a href="#9-10-3-C-程序的保守-Mark-amp-Sweep" class="headerlink" title="9.10.3 C 程序的保守 Mark &amp; Sweep"></a>9.10.3 C 程序的保守 Mark &amp; Sweep</h3><p>Mark&amp;Sweep 对 C 程序的垃圾收集是一种合适的方法，因为它可以就地工作，而不需要移动任何块。然而，C 语言为 isPtr 函数的实现造成了一些有趣的挑战。</p>
<p>第一，C 不会用任何类型信息来标记内存位置。因此，对 isPtr 没有一种明显的方式来判断它的输人参数 P 是不是一个指针。第二，即使我们知道 P 是一个指针，对 isPtr 也没有明显的方式来判断 P 是否指向一个已分配块的有效载荷中的某个位置。</p>
<p>对后一问题的解决方法是将已分配块集合维护成一棵平衡二叉树，这棵树保持着这样一个属性：左子树中的所有块都放在较小的地址处，而右子树中的所有块都放在较大的地址处。如图 9-53 所示，这就要求每个已分配块的头部里有两个附加字段(left 和 right)每个字段指向某个已分配块的头部。isPtr(ptr p)函数用树来执行对已分配块的二分查找。在每一步中，它依赖于块头部中的大小字段来判断 P 是否落在这个块的范围之内。</p>
<p><img src="/image/caspp/chapter9/9-53.jpg"><br>图 9-53 一棵已分配块的平衡树中的左右指针</p>
<p>平衡树方法保证会标记所有从根节点可达的节点，从这个意义上来说它是正确的。这是一个必要的保证，因为应用程序的用户当然不会喜欢把他们的已分配块过早地返回给空闲链表。然而，这种方法从某种意义上而言又是保守的，因为它可能不正确地标记实际上不可达的块，因此它可能不会释放某些垃圾。虽然这并不影响应用程序的正确性，但是这可能导致不必要的外部碎片。</p>
<p>C 程序的 Mark &amp; Sweep 收集器必须是保守的，其根本原因是 C 语言不会用类型信息来标记内存位置。因此，像 int 或者 float 这样的标量可以伪装成指针。例如，假设某个可达的已分配块在它的有效载荷中包含一个 int。其值碰巧对应于某个其他已分配块 b的有效载荷中的一个地址。对收集器而言，是没有办法推断出这个数据实际上是 int 而不是指针。因此，分配器必须保守地将块 b 标记为可达，尽管事实上它可能是不可达的。</p>
<h2 id="9-11-C-程序中常见的与内存有关的错误"><a href="#9-11-C-程序中常见的与内存有关的错误" class="headerlink" title="9.11 C 程序中常见的与内存有关的错误"></a>9.11 C 程序中常见的与内存有关的错误</h2><ul>
<li>间接引用坏指针</li>
<li>读未初始化的内存</li>
<li>允许栈缓冲区溢出</li>
<li>假设指针和它们指向的对象是相同大小的</li>
<li>造成错位错误</li>
<li>引用指针，而不是它所指向的对象</li>
<li>误解指针运算</li>
<li>引用不存在的变量</li>
<li>引用空闲堆块中的数据 </li>
<li>引起内存泄漏</li>
</ul>
<h2 id="9-12-小结"><a href="#9-12-小结" class="headerlink" title="9.12 小结"></a>9.12 小结</h2><p>虚拟内存是对主存的一个抽象。支持虚拟内存的处理器通过使用一种叫做虚拟寻址的间接形式来引用主存。处理器产生一个虚拟地址，在被发送到主存之前，这个地址被翻译成一个物理地址。从虚拟地址空间到物理地址空间的地址翻译要求硬件和软件紧密合作。专门的硬件通过使用页表来翻译虚拟地址，而页表的内容是由操作系统提供的。</p>
<p>虚拟内存提供三个重要的功能。第一，它在主存中自动缓存最近使用的存放磁盘上的虚拟地址空间的内容。虚拟内存缓存中的块叫做页。对磁盘上页的引用会触发缺页，缺页将控制转移到操作系统中的一个缺页处理程序。缺页处理程序将页面从磁盘复制到主存缓存，如果必要，将写回被驱逐的页。第二，虚拟内存简化了内存管理，进而又简化了链接、在进程间共享数据、进程的内存分配以及程序加载。最后，虚拟内存通过在每条页表条目中加人保护位，从而了简化了内存保护。地址翻译的过程必须和系统中所有的硬件缓存的操作集成在一起。大多数页表条目位于 L1 高速缓存中，但是一个称为 TLB 的页表条目的片上高速缓存，通常会消除访问在 L1 上的页表条目的开销。</p>
<p>现代系统通过将虚拟内存片和磁盘上的文件片关联起来，来初始化虚拟内存片，这个过程称为内存映射。内存映射为共享数据、创建新的进程以及加载程序提供了一种高效的机制。应用可以使用 mmap 函数来手工地创建和删除虚拟地址空间的区域。然而，大多数程序依赖于动态内存分配器，例如 malloc。它管理虚拟地址空间区域内一个称为堆的区域。动态内存分配器是一个感觉像系统级程序的应用级程序，它直接操作内存，而无需类型系统的很多帮助。分配器有两种类型。显式分配器要求应用显式地释放它们的内存块。隐式分配器（垃圾收集器）自动释放任何未使用的和不可达的块。</p>
<p>对于 C 程序员来说，管理和使用虚拟内存是一件困难和容易出错的任务。常见的错误示例包括：间接引用坏指针，读取未初始化的内存，允许栈缓冲区溢出，假设指针和它们指向的对象大小相同，引用指针而不是它所指向的对象，误解指针运算，引用不存在的变量，以及引起内存泄漏。</p>

  </div>
  </br>
  </br>
  
  <section id="comments" class="comments">
    <div class="valine-comment"></div>
<!--载入js，在</body>之前插入即可-->
<!--Leancloud 操作库:-->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<!--Valine 的核心代码库-->
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
new Valine({
    el: '.valine-comment',
    app_id: 'aVoW8Ns48PCL9aWpyaraklyz-gzGzoHsz',
    app_key: '5OofdgauZeSJ0SPHIgbbQ6fe',
    placeholder: '',
    visitor: 'true',
  })
</script>
  </section>
  
</article>
    </main>
    <footer id="footer">
  Copyright &copy;
  2023
  Yu Peng
  
  
    <a class="social-links" target="_blank" rel="noopener" href="https://github.com/yuhua2000"><i class="blogfont">&#xe6b7; </i></a>
  
    <a class="social-links" href="mailto:2651034096@qq.com"><i class="blogfont">&#xe61a; </i></a>
  
  
</footer>
    <!-- scripts -->

<script src="/scripts/main.js"></script>

  </body>
</html>